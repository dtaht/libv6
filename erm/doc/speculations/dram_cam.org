* Overview

ERM has a collection of ideas in it that might be foolish, crazy, or impossible
to implement in hardware - or all three. It is, in many cases, a collection of
oddball ideas that might or might not actually work in practice. Portions are
completely unimplementable using the hardware design tools at hand - in 1992
when I first started at designing it - and now, in 2016, where the world has
seemingly moved to massively distributed single clock domains on a very small
scale with wires being more of the problem than transistors at < 16nm.

There are also a few ideas that are not fully thought out. If I don't at least
write down the bits of the ideas as I have time, I'll never get around to
working on them more fully.

One of them is the idea of using lots and lots of very small but very wide cam
memories.

* Heat, generational memory and dram cams

ERM uses generational memory structures throughout, partially to handle nasty
concurrency problems, and partially due to being an abstract way to "let die"
data you don't need anymore. And - cut down on heat consumption. (and - to swap
in only data and programs in the cache on a software arch that you need. At
least in programs you tend to throw away 80% of the data or more - in a data
flow architecture - well - you just keep actively throwing it away and just
keep "hot" what you need. Actually, the sense of that is wrong - you "fling"
forward the data you are going to need, and let die the data you don't.)

One of the old ideas in ERM is the idea of using DRAM based cam, which seemed to
be a good idea (back in 2000). It had some nice properties - smaller, faster -
and some bad ones (hotter, and needing a refresh). That concept appears to have
died in the marketplace (and I don't know why) - and cam memory designs are a
high cost bit of IP you seemingly have to buy differently for every architecture
and not available on opencores. [[https://www.xilinx.com/support/documentation/application_notes/xapp1151_Param_CAM.pdf][XilinxCAM]] does, at least, have an "enhanced
ternary mode" - which basically reduces to some of the four valued logic I'd
like to use throughout erm. I find it ironic that folk still can't think of it
as 4 valued logic. Enhanced ternary mode. Sigh.

"Enhanced Ternary Mode: In this mode, bit X also matches either 1, 0, or X (1010
= 1X1X = 10XX) and is also referred to as a don’t care bit. Bit U does not match
any of the four possible bit values 1, 0, X, or U, and is referred to as an
unmatchable bit."

Anyway - back to DRAM cams. On the refresh front, if you haven't accessed the
cam in the x clock cycles you've been using it, thus you aren't using it
anymore, so just let it die and don't refresh it.

On the generational front, once you switch over to a new set of cams, the others
can die - just get powered down - don't refresh, either - until you need them again.

It's certainly feasible to just use static cams. But they must DIE on a schedule
to reduce heat generated by the architecture.

Writes on the xilinx circuit above take 16 clocks, so "rebuilding a cam" takes a
lot more time than accessing it. (1 clock). 

** The generational state machine

Everything has essentially a 4 state state machine in it and circulates through
those states on a collaborative basis. I begrudge C for not having a 2 bit type.

*** Active
*** Dying
*** Dead
*** Reloading

* Asynchronous circuits

Another really core idea in ERM is the concept of using async circuit design
throughout. You don't care how long an operation takes, but you do want it to
die on the first failure and return. (killing all the extra circuits you would
have used).

Perhaps some async design tools exist, but thus far, I've come up empty aside
from [[https://github.com/dudecc/chpsim][CHP]]. I came up empty in 92, too!

Everything today has these massively clocked central domains, and processors
that have explicit power states, (that are a pain in the arse to get in and out
of), and many tools are *enforcing* rigorous adherence to that centrally clocked
design.

Erm has interval timers. That's it. if you went to sleep, had a cache miss, or
anything else that took more or less time, the only way to know how long it took
is to check the interval timer. There's a sloppily synced clock, and any given
result can take variable time, and if you are late, you just get in line with
1024 different other potential queues.

you can't even get at the cycle timer on an arm box by default without specially
programming a special unit. This is nuts.

* Another CAM

"The Caltech Asynchronous Microprocessor (also know as CAM) is the world-first
asynchronous microprocessor. It was fabricated in 1988 by our research group at
Caltech. (The chip was taped-out in December 1988.) It is a 16-bit RISC machine
with 16 general-purpose registers. Its peak performance is 5 MIPS at 2V drawing
5.2mA of current, 18 MIPS at 5V drawing 45mA, and 26 MIPS at 10V drawing 105mA
in HP 1.6µm CMOS." -

http://www.async.caltech.edu/cam.html

The language that erm sort of looks like is "CHP":
http://www.async.caltech.edu/Pubs/PDF/25YearsAgo.pdf

http://www.async.caltech.edu/Pubs/PDF/chpasync2012.pdf

When that first async chip came out from caltech back in 1988, I said - "eureka!
this is the answer!" No central clock, in particular, means that the RFI
generated by such a chip is much lower, and then you can have a much more
sensitive wireless circuit than otherwise feasible. You have heat problems, you
slow down magically. You don't have heat problems, you speed up.

Power consumption is less, across the board (the numbers turned in above were
amazing)but all the async chips since then - and now - never made it out to open
source. And risc is a poor map for the instruction set - what Moore has done
with his forth processors was more appropo...

There are a bunch of really small adders in the design as well (3 or 4 bits).

http://www.cs.columbia.edu/~nowick/nowick-async97-speculation-completion-fin.pdf

* Xilinx vs Altera

I chose Xilinx over the other guys because they had a low cost chip that let you
hook up virtual memory to the fpga. Which so far, I haven't seen used
particularly well, or maybe I just misunderstand it. Intel bought Altera and
there are plans to integrate Xeon with those FPGAs - which sounds really cool,
except that I'm not sure they can pull it off. I really should take another look
at Altera.

* Synopsys

Seems to be the bottom feeder in grabbing up all the cool tools. They can't
possibly be well integrated or well maintained. 
